{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos la librería pandas que necesitamos para la lectura, conversión y limpieza de los datos.\n",
    "# -----------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "#Importamos librerías necesarias para la visualización.\n",
    "# -----------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Importamos librerías para localizar ruta archivos.\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# Imputación de nulos usando métodos avanzados estadísticos.\n",
    "# -----------------------------------------------------------------------\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "pd.set_option('display.max_columns', None) # para poder visualizar todas las columnas de los DataFrames\n",
    "# pd.set_option('display.max_rows', None) # para poder visualizar todas las filas de los DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>employeecount</th>\n",
       "      <th>employeenumber</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>MonthlyRate</th>\n",
       "      <th>NUMCOMPANIESWORKED</th>\n",
       "      <th>Over18</th>\n",
       "      <th>OverTime</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TOTALWORKINGYEARS</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WORKLIFEBALANCE</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YEARSWITHCURRMANAGER</th>\n",
       "      <th>SameAsMonthlyIncome</th>\n",
       "      <th>DateBirth</th>\n",
       "      <th>Salary</th>\n",
       "      <th>RoleDepartament</th>\n",
       "      <th>NUMBERCHILDREN</th>\n",
       "      <th>RemoteWork</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>29</td>\n",
       "      <td>No</td>\n",
       "      <td>travel_rarely</td>\n",
       "      <td>1389,0$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>20,0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>maNufaCturing direcTOr</td>\n",
       "      <td>1</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10195</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>No</td>\n",
       "      <td>11</td>\n",
       "      <td>3,0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10,0</td>\n",
       "      <td>1</td>\n",
       "      <td>3,0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994</td>\n",
       "      <td>1000000000$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>58</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>390,0$</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>422,0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>HEalTHCare REPrEsEntATiVE</td>\n",
       "      <td>3</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17056</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>13</td>\n",
       "      <td>3,0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3,0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1965</td>\n",
       "      <td>1000000000$</td>\n",
       "      <td>HEalTHCare REPrEsEntATiVE  -  Research &amp; Deve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>35</td>\n",
       "      <td>No</td>\n",
       "      <td>travel_frequently</td>\n",
       "      <td>nan$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>269,0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>laborAToRy teCHnIcIAn</td>\n",
       "      <td>2</td>\n",
       "      <td>Single</td>\n",
       "      <td>4425,0</td>\n",
       "      <td>15986</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>3,0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3,0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4425,0</td>\n",
       "      <td>1988</td>\n",
       "      <td>1000000000$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>36</td>\n",
       "      <td>No</td>\n",
       "      <td>travel_rarely</td>\n",
       "      <td>188,0$</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ReSEArcH sCIeNtist</td>\n",
       "      <td>4</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23293</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>3,0</td>\n",
       "      <td>3</td>\n",
       "      <td>80,0</td>\n",
       "      <td>0</td>\n",
       "      <td>8,0</td>\n",
       "      <td>6</td>\n",
       "      <td>3,0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1987</td>\n",
       "      <td>1000000000$</td>\n",
       "      <td>ReSEArcH sCIeNtist  -  Research &amp; Development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>24</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>567,0$</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Technical Degree</td>\n",
       "      <td>1</td>\n",
       "      <td>1646,0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ReSeaRch SCIEnTiSt</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3760,0</td>\n",
       "      <td>17218</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>3,0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6,0</td>\n",
       "      <td>2</td>\n",
       "      <td>3,0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3760,0</td>\n",
       "      <td>1999</td>\n",
       "      <td>1000000000$</td>\n",
       "      <td>ReSeaRch SCIEnTiSt  -  Research &amp; Development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>29</td>\n",
       "      <td>No</td>\n",
       "      <td>travel_frequently</td>\n",
       "      <td>1404,0$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-18</td>\n",
       "      <td>3</td>\n",
       "      <td>Technical Degree</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>sALES REprEsEntATive</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18203</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>No</td>\n",
       "      <td>15</td>\n",
       "      <td>3,0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3,0</td>\n",
       "      <td>5</td>\n",
       "      <td>3,0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994</td>\n",
       "      <td>1000000000$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>travel_frequently</td>\n",
       "      <td>793,0$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1371,0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>sales executiVE</td>\n",
       "      <td>4</td>\n",
       "      <td>Single</td>\n",
       "      <td>5071,0</td>\n",
       "      <td>20392</td>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>No</td>\n",
       "      <td>20</td>\n",
       "      <td>4,0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3,0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5071,0</td>\n",
       "      <td>1996</td>\n",
       "      <td>1000000000$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>non-travel</td>\n",
       "      <td>1283,0$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>1</td>\n",
       "      <td>1756,0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>sALEs EXEcUtIvE</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5147,0</td>\n",
       "      <td>10697</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>15</td>\n",
       "      <td>3,0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13,0</td>\n",
       "      <td>2</td>\n",
       "      <td>2,0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5147,0</td>\n",
       "      <td>1990</td>\n",
       "      <td>1000000000$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>31</td>\n",
       "      <td>No</td>\n",
       "      <td>travel_rarely</td>\n",
       "      <td>688,0$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>mAnageR</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25291</td>\n",
       "      <td>9</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>4,0</td>\n",
       "      <td>3</td>\n",
       "      <td>80,0</td>\n",
       "      <td>1</td>\n",
       "      <td>10,0</td>\n",
       "      <td>3</td>\n",
       "      <td>2,0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1992</td>\n",
       "      <td>1000000000$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192,0$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>544,0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ResearCH scIeNTiSt</td>\n",
       "      <td>4</td>\n",
       "      <td>Married</td>\n",
       "      <td>2654,0</td>\n",
       "      <td>9655</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>8,0</td>\n",
       "      <td>3</td>\n",
       "      <td>2,0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2654,0</td>\n",
       "      <td>1978</td>\n",
       "      <td>1000000000$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Attrition     BusinessTravel DailyRate                Department  \\\n",
       "107   29        No      travel_rarely   1389,0$                       NaN   \n",
       "690   58        No                NaN    390,0$   Research & Development    \n",
       "841   35        No  travel_frequently      nan$                       NaN   \n",
       "973   36        No      travel_rarely    188,0$   Research & Development    \n",
       "759   24        No                NaN    567,0$   Research & Development    \n",
       "1193  29        No  travel_frequently   1404,0$                       NaN   \n",
       "1035  27        No  travel_frequently    793,0$                       NaN   \n",
       "454   33        No         non-travel   1283,0$                       NaN   \n",
       "595   31        No      travel_rarely    688,0$                       NaN   \n",
       "1540  45        No                NaN    192,0$                       NaN   \n",
       "\n",
       "      DistanceFromHome  Education    EducationField  employeecount  \\\n",
       "107                 21          4     Life Sciences              1   \n",
       "690                  1          4     Life Sciences              1   \n",
       "841                -24          3           Medical              1   \n",
       "973                  7          4             Other              1   \n",
       "759                  2          1  Technical Degree              1   \n",
       "1193               -18          3  Technical Degree              1   \n",
       "1035                 2          1     Life Sciences              1   \n",
       "454                  2          3         Marketing              1   \n",
       "595                  7          3               NaN              1   \n",
       "1540                10          2     Life Sciences              1   \n",
       "\n",
       "     employeenumber  EnvironmentSatisfaction  Gender HourlyRate  \\\n",
       "107            20,0                        2       1         51   \n",
       "690           422,0                        4       0         32   \n",
       "841           269,0                        2       1         37   \n",
       "973             NaN                        2       0         65   \n",
       "759          1646,0                        1       1         32   \n",
       "1193            NaN                        3       1         84   \n",
       "1035         1371,0                        4       0         43   \n",
       "454          1756,0                        4       1         62   \n",
       "595             NaN                        3       0         44   \n",
       "1540          544,0                        1       0         69   \n",
       "\n",
       "      JobInvolvement  JobLevel                      JobRole  JobSatisfaction  \\\n",
       "107                4         3      maNufaCturing direcTOr                 1   \n",
       "690                1         2   HEalTHCare REPrEsEntATiVE                 3   \n",
       "841                3         2       laborAToRy teCHnIcIAn                 2   \n",
       "973                3         1          ReSEArcH sCIeNtist                 4   \n",
       "759                3         1          ReSeaRch SCIEnTiSt                 4   \n",
       "1193               3         1        sALES REprEsEntATive                 4   \n",
       "1035               1         2             sales executiVE                 4   \n",
       "454                3         2             sALEs EXEcUtIvE                 2   \n",
       "595                2         3                     mAnageR                 4   \n",
       "1540               3         1          ResearCH scIeNTiSt                 4   \n",
       "\n",
       "     MaritalStatus MonthlyIncome  MonthlyRate  NUMCOMPANIESWORKED Over18  \\\n",
       "107       Divorced           NaN        10195                   1      Y   \n",
       "690       Divorced           NaN        17056                   2    NaN   \n",
       "841         Single        4425,0        15986                   5    NaN   \n",
       "973         Single           NaN        23293                   2      Y   \n",
       "759            NaN        3760,0        17218                   1    NaN   \n",
       "1193           NaN           NaN        18203                   1      Y   \n",
       "1035        Single        5071,0        20392                   3      Y   \n",
       "454            NaN        5147,0        10697                   8    NaN   \n",
       "595       Divorced           NaN        25291                   9      Y   \n",
       "1540       Married        2654,0         9655                   3    NaN   \n",
       "\n",
       "     OverTime  PercentSalaryHike PerformanceRating  RelationshipSatisfaction  \\\n",
       "107        No                 11               3,0                         3   \n",
       "690       Yes                 13               3,0                         4   \n",
       "841       NaN                 11               3,0                         4   \n",
       "973       NaN                 18               3,0                         3   \n",
       "759       NaN                 13               3,0                         3   \n",
       "1193       No                 15               3,0                         2   \n",
       "1035       No                 20               4,0                         2   \n",
       "454        No                 15               3,0                         4   \n",
       "595       NaN                 21               4,0                         3   \n",
       "1540       No                 21               NaN                         4   \n",
       "\n",
       "     StandardHours  StockOptionLevel TOTALWORKINGYEARS  TrainingTimesLastYear  \\\n",
       "107            NaN                 1              10,0                      1   \n",
       "690            NaN                 1               NaN                      2   \n",
       "841            NaN                 0               NaN                      5   \n",
       "973           80,0                 0               8,0                      6   \n",
       "759            NaN                 0               6,0                      2   \n",
       "1193           NaN                 1               3,0                      5   \n",
       "1035           NaN                 0               NaN                      3   \n",
       "454            NaN                 0              13,0                      2   \n",
       "595           80,0                 1              10,0                      3   \n",
       "1540           NaN                 2               8,0                      3   \n",
       "\n",
       "     WORKLIFEBALANCE  YearsAtCompany YearsInCurrentRole  \\\n",
       "107              3,0              10                NaN   \n",
       "690              3,0               5                NaN   \n",
       "841              3,0               6                NaN   \n",
       "973              3,0               6                NaN   \n",
       "759              3,0               6                NaN   \n",
       "1193             3,0               3                NaN   \n",
       "1035             3,0               6                NaN   \n",
       "454              2,0              11                NaN   \n",
       "595              2,0               5                NaN   \n",
       "1540             2,0               2                NaN   \n",
       "\n",
       "      YearsSinceLastPromotion  YEARSWITHCURRMANAGER SameAsMonthlyIncome  \\\n",
       "107                         8                     8                 NaN   \n",
       "690                         1                     2                 NaN   \n",
       "841                         1                     2              4425,0   \n",
       "973                         0                     1                 NaN   \n",
       "759                         1                     3              3760,0   \n",
       "1193                        0                     2                 NaN   \n",
       "1035                        0                     0              5071,0   \n",
       "454                         1                     7              5147,0   \n",
       "595                         0                     1                 NaN   \n",
       "1540                        0                     2              2654,0   \n",
       "\n",
       "      DateBirth       Salary  \\\n",
       "107        1994  1000000000$   \n",
       "690        1965  1000000000$   \n",
       "841        1988  1000000000$   \n",
       "973        1987  1000000000$   \n",
       "759        1999  1000000000$   \n",
       "1193       1994  1000000000$   \n",
       "1035       1996  1000000000$   \n",
       "454        1990  1000000000$   \n",
       "595        1992  1000000000$   \n",
       "1540       1978  1000000000$   \n",
       "\n",
       "                                        RoleDepartament  NUMBERCHILDREN  \\\n",
       "107                                                 NaN             NaN   \n",
       "690    HEalTHCare REPrEsEntATiVE  -  Research & Deve...             NaN   \n",
       "841                                                 NaN             NaN   \n",
       "973      ReSEArcH sCIeNtist  -  Research & Development              NaN   \n",
       "759      ReSeaRch SCIEnTiSt  -  Research & Development              NaN   \n",
       "1193                                                NaN             NaN   \n",
       "1035                                                NaN             NaN   \n",
       "454                                                 NaN             NaN   \n",
       "595                                                 NaN             NaN   \n",
       "1540                                                NaN             NaN   \n",
       "\n",
       "     RemoteWork  \n",
       "107           0  \n",
       "690        True  \n",
       "841         Yes  \n",
       "973           1  \n",
       "759           0  \n",
       "1193      False  \n",
       "1035      False  \n",
       "454        True  \n",
       "595         Yes  \n",
       "1540        Yes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Abrimos el csv y lo convertimos a un DataFrame.\n",
    "df_HR = pd.read_csv('/Users/Tania_1/Desktop/ADALAB/MODULO_3/project-da-promo-angela-modulo-3-team-3/ETL/data/input_data/HR_RAW_DATA.csv', index_col= 0)\n",
    "df_HR.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FASE 1.\n",
    "#Creamos la función para leer el archivo csv.\n",
    "def lectura_archivo(csv):\n",
    "    df = pd.read_csv(csv, index_col= 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lectura_archivo('HR_RAW_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la función para explorar los datos. \n",
    "\n",
    "def exploracion_datos(df):\n",
    "    print('_____________ INFORMACIÓN GENERAL DEL DATAFRAME ____________\\n')\n",
    "    print(df.info())\n",
    "\n",
    "    print('___________________ FORMA DEL DATAFRAME ____________________\\n')\n",
    "    \n",
    "    print(f\"El número de filas que tenemos es de {df.shape[0]}.\\nEl número de columnas es de {df.shape[1]}\\n\")\n",
    "    \n",
    "\n",
    "    print('_______________ NULOS, ÚNICOS Y DUPLICADOS _________________\\n')\n",
    "    \n",
    "    print('La cantidad de valores NULOS por columna es de:\\n')\n",
    "    print(df.isnull().sum())\n",
    "    print('____________________________________________________________\\n')\n",
    "\n",
    "    print('La cantidad de valores ÚNICOS por columna es de:\\n')\n",
    "        \n",
    "    for columna in df.columns:\n",
    "        cantidad_valores_unicos = len(df[columna].unique())\n",
    "    \n",
    "        print(f'La columna {columna}: {cantidad_valores_unicos}')\n",
    "\n",
    "    \"\"\" Otra forma más rápida de obtener la lista de valores únicos por columna es usando df.nunique()\"\"\"\n",
    "\n",
    "    print('____________________________________________________________\\n')\n",
    "\n",
    "    print('La cantidad de valores DUPLICADOS por columna es de:\\n')\n",
    "\n",
    "    \"\"\"En análisis posteriores hemos detectado que hay columnas con valores duplicados que nos interesa filtrar, \n",
    "    así que vamos a realizar otro bucle for para iterar por todas las columnas del DF y obtener los duplicados de cada una de ellas.\"\"\"\n",
    "\n",
    "    for columna in df.columns:\n",
    "        cantidad_duplicados = df[columna].duplicated().sum()\n",
    "    \n",
    "        print(f'La columna {columna}: {cantidad_duplicados}')\n",
    "\n",
    "\n",
    "    print('____________________ RESUMEN ESTADÍSTICO ____________________')\n",
    "    print('____________________ Variables Numéricas __________________\\n')\n",
    "    print(df.describe().T)\n",
    "    \n",
    "    print('___________________ Variables Categóricas _________________\\n')\n",
    "    print(df.describe(include='object').T)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploracion_datos(df_HR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FASE 2\n",
    "\"\"\" ¿Qué hacemos con la columna del id de empleados que tiene duplicados? \"\"\"\n",
    "df_HR['employeenumber'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#employeecount: esta columna tiene el mismo valor para todas las filas, por lo que es redundante y se puede eliminar.¿¿??\n",
    "df_HR['employeecount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna \"employeecount\"\n",
    "df_HR.drop(columns='employeecount', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMBERCHILDREN: Tiene solo valores nulos, se puede eliminar.\n",
    "df_HR['NUMBERCHILDREN'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna \"NUMBERCHILDREN\"\n",
    "df_HR.drop(columns='NUMBERCHILDREN', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SameAsMonthlyIncome: parece un duplicado de la columna MonthlyIncome,se puede eliminar. \n",
    "df_HR[['SameAsMonthlyIncome', 'MonthlyIncome', 'MonthlyRate', 'HourlyRate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna\n",
    "df_HR.drop(columns='SameAsMonthlyIncome', inplace= True)\n",
    "#Buscamos nombre columnas para comprobar que la hemos eliminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salary: Tiene un solo valor repetido, por lo que se puede eliminar también.\n",
    "df_HR['Salary'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna \"Salary\"\n",
    "df_HR.drop(columns='Salary', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reemplazamos los valores 1 y 0 de la columna Gender por \"M\" de masculino y \"F\" de femenino, usando loc.\n",
    "\n",
    "df_HR.loc[df_HR['Gender'] == 0, 'Gender'] = 'M'\n",
    "df_HR.loc[df_HR['Gender'] == 1, 'Gender'] = 'F'\n",
    "\n",
    "print(df_HR['Gender'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para cambiar a FLOAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la función 'cambiar comas'\n",
    "\n",
    "lista_tofloat = ['DailyRate', 'HourlyRate', 'MonthlyIncome']\n",
    "\n",
    "def cambiar_comas(cadena):\n",
    "     # Remover el símbolo $, reemplazar comas por puntos\n",
    "     # Usar expresiones regulares para mantener solo los números y puntos\n",
    "    try:\n",
    "    # Remover cualquier caracter que no sea dígito o coma\n",
    "        cleaned_string = re.sub(r'[^\\d,]', '', cadena)\n",
    "        # Reemplazar comas por puntos\n",
    "        cleaned_string = cleaned_string.replace(\",\", \".\")\n",
    "        # Convertir a float\n",
    "        return float(cleaned_string)\n",
    "    except:\n",
    "        return np.nan # Devuelve un np.nan si hay un valor inválido\n",
    "\n",
    "# Aplicar la función a cada columna en la lista\n",
    "for col in lista_tofloat:\n",
    "    df_HR[col] = df_HR[col].apply(cambiar_comas)\n",
    "\n",
    "\n",
    "# Comprobamos que la columna, que antes era de tipo string, ahora es float64.\n",
    "df_HR[lista_tofloat].dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lo guardo para que se guarden los datos\n",
    "\n",
    "df_HR.to_csv(\"df_HR_limpio.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para cambiar a INT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Creamos la función 'cambiar comas'\n",
    "\n",
    "lista_toint = ['WORKLIFEBALANCE']\n",
    "\n",
    "def cambiar_comas(cadena):\n",
    "     # Remover el símbolo $, reemplazar comas por puntos\n",
    "     # Usar expresiones regulares para mantener solo los números y puntos\n",
    "    try:\n",
    "    # Remover cualquier caracter que no sea dígito o coma\n",
    "        cleaned_string = re.sub(r'[^\\d,]', '', cadena)\n",
    "        # Reemplazar comas por puntos\n",
    "        cleaned_string = cleaned_string.replace(\",\", \".\")\n",
    "        # Convertir a float\n",
    "        return int(cleaned_string)\n",
    "    except:\n",
    "        return np.nan # Devuelve un np.nan si hay un valor inválido\n",
    "\n",
    "# Aplicar la función a cada columna en la lista\n",
    "for col in lista_toint:\n",
    "    #convertir a int\n",
    "    df_HR[col] = df_HR[col].apply(cambiar_comas).astype('Int64')\n",
    "\n",
    "\n",
    "# Comprobamos que la columna, que antes era de tipo string, ahora es float64.\n",
    "df_HR[lista_toint].dtypes\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def comasapuntos(num):\n",
    "    try:\n",
    "        return float(num.replace(\",\", \".\"))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "columnas = [\"WORKLIFEBALANCE\"]\n",
    "\n",
    "for col in columnas:\n",
    "    df_HR[col] = df_HR[col].apply(comasapuntos)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR['WORKLIFEBALANCE'] = df_HR['WORKLIFEBALANCE'].replace('NaN', pd.NA)\n",
    "\n",
    "# Convertir los valores en 'WORKLIFEBALANCE' a float y manejar los NaN\n",
    "df_HR['WORKLIFEBALANCE'] = df_HR['WORKLIFEBALANCE'].astype(str).str.replace(',', '.').astype(float)\n",
    "\n",
    "# Convertir los valores a int, ignorando los NaN\n",
    "df_HR['WORKLIFEBALANCE'] = df_HR['WORKLIFEBALANCE'].astype('Int64')\n",
    "df_HR['WORKLIFEBALANCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasar a csv para que se guarde\n",
    "\n",
    "df_HR.to_csv('df_HR_limpio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR = pd.read_csv('df_HR_limpio.csv')\n",
    "df_HR.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ver los datos unicos\n",
    "\n",
    "df_HR['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiamos el tipo de dato de la columna Age para que sea interger.\n",
    "\n",
    "df_HR.loc[df_HR['Age'] == 'forty-seven', 'Age'] = '47'\n",
    "df_HR.loc[df_HR['Age'] == 'fifty-eight', 'Age'] = '58'\n",
    "df_HR.loc[df_HR['Age'] == 'thirty-six', 'Age'] = '36'\n",
    "df_HR.loc[df_HR['Age'] == 'fifty-five', 'Age'] = '55'\n",
    "df_HR.loc[df_HR['Age'] == 'fifty-two', 'Age'] = '52'\n",
    "df_HR.loc[df_HR['Age'] == 'thirty-one', 'Age'] = '31'\n",
    "df_HR.loc[df_HR['Age'] == 'thirty', 'Age'] = '30'\n",
    "df_HR.loc[df_HR['Age'] == 'twenty-six', 'Age'] = '26'\n",
    "df_HR.loc[df_HR['Age'] == 'thirty-seven', 'Age'] = '37'\n",
    "df_HR.loc[df_HR['Age'] == 'thirty-two', 'Age'] = '32'\n",
    "df_HR.loc[df_HR['Age'] == 'thirty-seven', 'Age'] = '37'\n",
    "df_HR.loc[df_HR['Age'] == 'twenty-four', 'Age'] = '24'\n",
    "\n",
    "df_HR['Age']= df_HR['Age'].astype(int)\n",
    "df_HR['Age'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buscamos los valores negativos de la columna 'DistanceFromHome'\n",
    "valores_negativos = df_HR[df_HR['DistanceFromHome'] < 0]['DistanceFromHome']\n",
    "print(valores_negativos)\n",
    "print('_________________________________________________')\n",
    "print(f'Hay {valores_negativos.shape[0]} filas con valores negativos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sustituimos valores negativos por positivos\n",
    "df_HR.loc[df_HR['DistanceFromHome'] < 0, 'DistanceFromHome'] = df_HR['DistanceFromHome'].abs()\n",
    "\n",
    "#Comprobamos que ya no hay valores negativos\n",
    "df_HR[df_HR['DistanceFromHome'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corregimos errores tipográficos en la columna MaritalStatus.\n",
    "df_HR['MaritalStatus'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como 'Marreid'.\n",
    "df_HR.loc[df_HR['MaritalStatus'] == 'Marreid', 'MaritalStatus'] = 'Married'\n",
    "df_HR['MaritalStatus'].unique()\n",
    "\n",
    "#O 'divorced'.\n",
    "df_HR.loc[df_HR['MaritalStatus'] == 'divorced', 'MaritalStatus'] = 'Divorced'\n",
    "df_HR['MaritalStatus'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Mirar qué otras columnas podemos cambiar de typo porque no estén en el correcto, como NUMBERCHILDRENS.\n",
    "Ver si alguna otra columna tiene muchos nulos y no nos interesa (de cara a eliminarla). \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FASE 4\n",
    "#Seudocódigo.\n",
    "\"\"\" Usar como filtro los valores de la columna **Attrition**. Los valores == YES han abandonado la empresa. \n",
    "    Buscar su nivel de Satisfacción. Columnas Age, Gender, EnviromentSatisfaction, JobInvolvement, \n",
    "    JobSatisfaction, 'RelationshipSatisfaction, WORKLIFEBALANCE, YearsSinceLastPromotion, ¿ YEARSWITHCURRMANAGER ?, \n",
    "    Salary, RoleDepartament, NUMBERCHILDREN, DistanceFromHome - RemoteWork. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR.to_csv('df_HR_limpio.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABRO el nuevo archivo, el limpio para seguir trabajando\n",
    "\n",
    "df_limpio = pd.read_csv('df_HR_limpio.csv', index_col= 0)\n",
    "df_limpio.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para mapear los valores a 'yes' y 'no', RemoteWork\n",
    "def map_values(value):\n",
    "    if str(value).lower() in ['1', 'true', 'yes']:\n",
    "        return 'yes'\n",
    "    elif str(value).lower() in ['0', 'false', 'no']:\n",
    "        return 'no'\n",
    "    else:\n",
    "        return value  \n",
    "\n",
    "# Aplicar la función a la columna\n",
    "df_limpio['RemoteWork'] = df_limpio['RemoteWork'].apply(map_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpio.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpio.to_csv('df_HR_limpio.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR = pd.read_csv('df_HR_limpio.csv', index_col= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corregir mayusculas y minusculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR[\"JobRole\"] = df_HR[\"JobRole\"].str.title()\n",
    "df_HR[\"RoleDepartament\"] = df_HR[\"RoleDepartament\"].str.title()\n",
    "df_HR.rename(columns={'TOTALWORKINGYEARS': 'TotalWorkingYears'}, inplace=True)\n",
    "df_HR.rename(columns={'employeenumber': 'EmployeeNumber'}, inplace=True)\n",
    "df_HR.rename(columns={'NUMCOMPANIESWORKED': 'NumCompaniesWorked'}, inplace=True)\n",
    "df_HR.rename(columns={'WORKLIFEBALANCE': 'WorkLifeBalance'}, inplace=True)\n",
    "df_HR.rename(columns={'YEARSWITHCURRMANAGER': 'YearsWithCurrManager'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR.to_csv(\"df_HR_limpio.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos tres columna más\n",
    "lista_eliminar = [\"Over18\", \"StandardHours\", \"RoleDepartament\", \"Department\", \"YearsInCurrentRole\"]\n",
    "df_HR.drop(columns= lista_eliminar, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN DE CONTEO DE FRECUENCIAS DE CADA COLUMNA\n",
    "\n",
    "# EJECUTAR Y ABRIR EN TEXT EDITOR PARA VISUALIZAR LOS RESULTADOS EN UN ARCHIVO INDEPENDIENTE\n",
    "\n",
    "def count_frequencies(df):\n",
    "    # Creamos un diccionario para almacenar los resultados\n",
    "    frequency_counts = {}\n",
    "    \n",
    "    # Recorremos todas las columnas del DataFrame\n",
    "    for column in df_HR.columns:\n",
    "        # Aplicar .value_counts() a cada columna y almacenarlo en el diccionario\n",
    "        frequency_counts[column] = df[column].value_counts()\n",
    "    \n",
    "    return frequency_counts\n",
    "\n",
    "# Llamamos a la función y obtenemos el conteo de frecuencia de cada columna\n",
    "frequency_counts = count_frequencies(df_HR)\n",
    "\n",
    "# Mostramos los resultados\n",
    "for column, counts in frequency_counts.items():\n",
    "    print(f\"Conteo de frecuencias para la columna {column}:\")\n",
    "    print(counts)\n",
    "    print()  # Línea en blanco para separar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los duplicados de la columna EmployeeNumber\n",
    "df_HR = df_HR.drop_duplicates(subset=['EmployeeNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que se han eliminado los nulos\n",
    "df_HR[\"EmployeeNumber\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Para obtener los duplicados de todas las columnas\n",
    "\n",
    "for columna in df_HR:\n",
    "    num_filas_duplicadas = df_HR[columna].duplicated().sum()\n",
    "    print(f'{columna.upper()}: {num_filas_duplicadas}')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para obtener los nulos de todas las columnas\n",
    "\n",
    "for columna in df_HR:\n",
    "    num_filas_nulas = df_HR[columna].isnull().sum()\n",
    "    print(f'{columna.upper()}: {num_filas_nulas}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestión de nulos de columnas categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el porcentaje de nulos que tenemos para cada columna categórica\n",
    "porc_nulos = (df_HR.isnull().sum() / df_HR.shape[0]) * 100\n",
    "porc_nulos\n",
    "\n",
    "# Lo convertimos a DataFrame\n",
    "df_nulos = pd.DataFrame(porc_nulos, columns = [\"%_nulos\"])\n",
    "\n",
    "# Filtramos el DataFrame para quedarnos solo con aquellas columnas que tengan nulos\n",
    "df_nulos[df_nulos[\"%_nulos\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la lista de columnas categóricas que tienen nulos\n",
    "nulos_esta_cat = df_HR[df_HR.columns[df_HR.isnull().any()]].select_dtypes(include = \"O\").columns\n",
    "print(\"Las columnas categóricas que tienen nulos son : \\n \")\n",
    "print(nulos_esta_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacamos el 'value_counts()' de cada una de las columnas categóricas que tienen nulos para saber como es la distribución de sus categorías\n",
    "for col in nulos_esta_cat:\n",
    "    print(f\"La distribución de las categorías para la columna {col.upper()}\")\n",
    "    display(df_HR[col].value_counts() / df_HR.shape[0] * 100)  # display es una función utilizada para mostrar objetos de manera más legible en Jupyter Notebooks o entornos similares. \n",
    "    print(\"........................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustituimos los valores nulos de las siguientes columnas por \"Unkown\", ya que no hay mayorías claras que nos permitan imputar.\n",
    "\n",
    "columnas_desconocido = ['BusinessTravel', 'EducationField', 'EmployeeNumber',\n",
    "       'MaritalStatus', 'OverTime', 'PerformanceRating', 'TotalWorkingYears']\n",
    "    \n",
    "    \n",
    "for columna in columnas_desconocido:\n",
    "    \n",
    "    # reemplazamos los nulos por el valor Unknown para cada una de las columnas de la lista\n",
    "    df_HR[columna] = df_HR[columna].fillna(\"Unknown\")\n",
    "    \n",
    "# comprobamos si quedan nulos en las columnas categóricas. \n",
    "print(\"Después del reemplazo usando 'fillna' quedan los siguientes nulos\")\n",
    "df_HR[columnas_desconocido].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestión de nulos de columnas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la lista de columnas numericas que tienen nulos\n",
    "nulos_esta_num = df_HR[df_HR.columns[df_HR.isnull().any()]].select_dtypes(include = np.number).columns\n",
    "print(\"Las columnas numéricas que tienen nulos son : \\n \")\n",
    "print(nulos_esta_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el porcentaje de nulos que tenemos en cada una de las columnas numericas\n",
    "df_HR[nulos_esta_num].isnull().sum() / df_HR.shape[0] *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un Boxplot para ver la distribución de los datos\n",
    "plt.figure(figsize=(5, 2.5))\n",
    "sns.boxplot(x=df_HR['DailyRate'])\n",
    "plt.title('Boxplot DailyRate')\n",
    "plt.xlabel('Valor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como la distribución de los datos es aproximadamente simétrica (los datos se distribuyen uniformemente alrededor del centro), la media es una buena medida central\n",
    "df_HR['DailyRate'].fillna(df_HR['DailyRate'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un Boxplot para ver la distribución de los datos\n",
    "plt.figure(figsize=(5, 2.5))\n",
    "sns.boxplot(x=df_HR['HourlyRate'])\n",
    "plt.title('Boxplot HourlyRate')\n",
    "plt.xlabel('Valor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como la distribución de los datos es aproximadamente simétrica (los datos se distribuyen uniformemente alrededor del centro), la media es una buena medida central\n",
    "df_HR['HourlyRate'].fillna(df_HR['HourlyRate'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un Boxplot para ver la distribución de los datos\n",
    "plt.figure(figsize=(5, 2.5))\n",
    "sns.boxplot(x=df_HR['MonthlyIncome'])\n",
    "plt.title('Boxplot MonthlyIncome')\n",
    "plt.xlabel('Valor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Como la distribución de los datos es asimétrica, imputamos con la mediana\n",
    "df_HR['MonthlyIncome'].fillna(df_HR['MonthlyIncome'].median(), inplace=True)\"\"\"\n",
    "\n",
    "# Como el porcentaje de nulos es tan alto usaremos el método IterativeImputer, algo más preciso que la media y la meediana\n",
    "# Instanciamos IterativeImputer\n",
    "imputer_iterative = IterativeImputer(max_iter=20, random_state=42)\n",
    "\n",
    "# Ajustamos y transformamos los datos\n",
    "imputer_iterative_imputado = imputer_iterative.fit_transform(df_HR[[\"MonthlyIncome\"]])\n",
    "\n",
    "# Comprobamos el array imputado\n",
    "print(\"\\nArray imputado:\")\n",
    "print(imputer_iterative_imputado)\n",
    "\n",
    "# Convertimos el resultado de vuelta a un DataFrame\n",
    "df_HR[\"MonthlyIncome\"] = imputer_iterative_imputado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un Boxplot para ver la distribución de los datos\n",
    "plt.figure(figsize=(5, 2.5))\n",
    "sns.boxplot(x=df_HR['WorkLifeBalance'])\n",
    "plt.title('Boxplot WorkLifeBalance')\n",
    "plt.xlabel('Valor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como la distribución de los datos es aproximadamente simétrica (los datos se distribuyen uniformemente alrededor del centro), la media es una buena medida central\n",
    "df_HR['WorkLifeBalance'].fillna(df_HR['WorkLifeBalance'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que ahora ya no hay valores nulos en esas columnas\n",
    "nulos_esta_num = df_HR[df_HR.columns[df_HR.isnull().any()]].select_dtypes(include = np.number).columns\n",
    "print(\"Las columnas numéricas que tienen nulos son : \\n \")\n",
    "print(nulos_esta_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HR.to_csv('df_HR_limpio.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear los csv para importarlos como tablas en sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos las columnas que queremos en cada variable \n",
    "\n",
    "employee = ['Age', 'Gender', 'MaritalStatus', 'DateBirth', 'Education', 'EducationField', 'Attrition', 'BusinessTravel', 'DistanceFromHome' ]\n",
    "job_details = ['JobRole','JobLevel', 'NumCompaniesWorked', 'TotalWorkingYears', 'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n",
    "compensation = ['DailyRate','HourlyRate','MonthlyIncome','MonthlyRate','StockOptionLevel','PercentSalaryHike','OverTime','TrainingTimesLastYear','RemoteWork']\n",
    "satisfaction = ['EnvironmentSatisfaction','JobInvolvement','JobSatisfaction','RelationshipSatisfaction','WorkLifeBalance','PerformanceRating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el CSV y seleccionar solo las columnas deseadas\n",
    "df = pd.read_csv('df_HR_limpio.csv', usecols=employee)\n",
    "df1 = pd.read_csv('df_HR_limpio.csv', usecols=job_details)\n",
    "df2 = pd.read_csv('df_HR_limpio.csv', usecols=compensation)\n",
    "df3 = pd.read_csv('df_HR_limpio.csv', usecols=satisfaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Employees.csv', index=False)\n",
    "df1.to_csv('JobDetails.csv', index=False)\n",
    "df2.to_csv('Compensation.csv', index=False)\n",
    "df3.to_csv('Satisfaction.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_work = pd.read_csv('Compensation.csv')\n",
    "remote_work.sample(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
